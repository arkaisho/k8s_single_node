{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing external access to services in a cluster\n",
    "A good way to facilitate and organize the entry of information and access to cluster is by creating an [Ingress](https://kubernetes.io/docs/concepts/services-networking/ingress/).\n",
    "> \"A ingress is an API object that manages external access to the services in a cluster, typically HTTP. Ingress may provide load balancing, SSL termination and name-based virtual hosting.\"\n",
    "\n",
    "Ingresses allows you to route and expose acess and traffic through the cluster to external acess under a single ip adress. To make a ingress to work you must have:\n",
    "\n",
    "1. Services to organize and route (we will use some basic examples)\n",
    "2. An Ingress controller (k3s have the traefik ingress controller set up by default)\n",
    "\n",
    "After getting this requirements you can apply a manifest file with the instructions to route the incomming requests to they respective services. This notebook is based on the [kubernetes documentation](https://kubernetes.io/docs/concepts/services-networking/ingress/) and in this [simple tutorial](https://matthewpalmer.net/kubernetes-app-developer/articles/kubernetes-ingress-guide-nginx-example.html) about how to configure a simple Ingress to acess many services.\n",
    "\n",
    "##  1 Creating basics servers and services\n",
    "\n",
    "First let's create two simple applications, an nginx and an flask servers, and their respective services. We will be using the manifest files in the \"issue7\" folder to make the process faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykube\n",
    "import yaml,json\n",
    "\n",
    "api = pykube.HTTPClient(pykube.KubeConfig.from_file(\"k3s.yaml\"))\n",
    "\n",
    "nginx_deployment = open(\"issue7/nginx/deployment.yaml\", \"r\")\n",
    "nginx_service = open(\"issue7/nginx/service.yaml\", \"r\")\n",
    "flask_deployment = open(\"issue7/flask/deployment.yaml\", \"r\")\n",
    "flask_service = open(\"issue7/flask/service.yaml\", \"r\")\n",
    "\n",
    "specs = []\n",
    "\n",
    "specs.append(yaml.load(nginx_deployment.read(), Loader=yaml.FullLoader))\n",
    "specs.append(yaml.load(nginx_service.read(), Loader=yaml.FullLoader))\n",
    "specs.append(yaml.load(flask_deployment.read(), Loader=yaml.FullLoader))\n",
    "specs.append(yaml.load(flask_service.read(), Loader=yaml.FullLoader))\n",
    "\n",
    "for spec in specs:\n",
    "    if spec['kind'] == 'Service':\n",
    "        pykube.Service(api,spec).create()\n",
    "    elif spec['kind'] == 'Deployment':\n",
    "        pykube.Deployment(api,spec).create()\n",
    "    \n",
    "nginx_deployment.close()\n",
    "nginx_service.close()\n",
    "flask_deployment.close()\n",
    "flask_service.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Configuring the Ingress\n",
    "Once the k3s cluster already have the traefik ingress controller we don't need to set up this. We can step up to the Ingress specification and test. The code below describe the rules for a Ingress to route the incomming requests on the localhost to \"flask\" and \"nginx\" services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingress = {\n",
    "  \"apiVersion\": \"extensions/v1beta1\", \n",
    "  \"kind\": \"Ingress\", \n",
    "  \"metadata\": {\n",
    "    \"name\": \"ingress-example\", \n",
    "    \"annotations\": {\n",
    "      \"ingress.kubernetes.io/rewrite-target\": \"/\"\n",
    "    }\n",
    "  },\n",
    "  \"spec\": {\n",
    "    \"rules\": [\n",
    "      {\n",
    "        \"http\": {\n",
    "          \"paths\": [\n",
    "            {\n",
    "              \"path\": \"/nginx\", \n",
    "              \"backend\": {\n",
    "                \"serviceName\": \"nginx\", \n",
    "                \"servicePort\": 8000\n",
    "              }\n",
    "            }, \n",
    "            {\n",
    "              \"path\": \"/flask\", \n",
    "              \"backend\": {\n",
    "                \"serviceName\": \"flask\", \n",
    "                \"servicePort\": 5000\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }, \n",
    "}\n",
    "pykube.Ingress(api,ingress).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the annotation [ingress.kubernetes.io/rewrite-target](https://kubernetes.github.io/ingress-nginx/user-guide/nginx-configuration/annotations/#rewrite), it says to the ingress to redirect the request to the \"/\" path of the services.\n",
    "\n",
    "You now can test the ingress by acessing [localhost/flask](http://localhost/flask) or [localhost/nginx](http://localhost/nginx) urls.\n",
    "> 1. You can also acess nginx error file by specifyng the 50x.html path in the request [localhost/nginx/50x.html](http://localhost/nginx/50x.html)\n",
    "> 2. If you try to acess a [wrong path](http://localhost/flask/wrong-url) in the flask application it will show the flask app error message instead the [nginx error](http://localhost/nginx/wrong-path) message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Clean up the cluster\n",
    "Run the below cell to delete the services, deployments and the ingress created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for spec in specs:\n",
    "    if spec['kind'] == 'Service':\n",
    "        pykube.Service(api,spec).delete()\n",
    "    elif spec['kind'] == 'Deployment':\n",
    "        pykube.Deployment(api,spec).delete()\n",
    "pykube.Ingress(api,ingress).delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Using the ingress to expose the dask interface\n",
    "One usefull thing to do with a Ingress is expose the dask's many interfaces of the scheduler and workers. Let's create a dask cluster with dask-kubernetes (like we did in Issue6) and try to expose his interface with an Ingress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Create the dask cluster\n",
    "Run the two cells bellow to create a dask single worker cluster and his client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n",
      "distributed.scheduler - INFO - Clear task state\n",
      "distributed.scheduler - INFO -   Scheduler at:    tcp://10.42.0.11:46447\n",
      "distributed.scheduler - INFO -   dashboard at:                     :8787\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster\n",
    "\n",
    "file = open(\"daskKubernetes/worker.yaml\", 'r')\n",
    "worker = yaml.load(file.read(), Loader=yaml.FullLoader)\n",
    "file.close()\n",
    "\n",
    "worker['spec']['volumes'] = [{'name':'storage','persistentVolumeClaim':{'claimName':'claim'}}]\n",
    "worker['spec']['containers'][0]['volumeMounts'] = [{'name':'storage','mountPath':'/home/arkaisho'}]\n",
    "\n",
    "cluster = KubeCluster.from_dict(worker)\n",
    "cluster.scale(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://10.42.0.11:46447</li>\n",
       "  <li><b>Dashboard: </b><a href='http://10.42.0.11:8787/status' target='_blank'>http://10.42.0.11:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>4.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://10.42.0.11:46447' processes=1 threads=2, memory=4.00 GB>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Create the service and the ingress\n",
    "In order to make the ingress route to the right place, we must have an service exposing the application that we want to reach. In this case, we first have to expose the dask scheduler dashboard with one service (we will use the ClusterIP type to show that we can expose services that are only visible inside the cluster using the Ingress for outsiders access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = {\n",
    "    \"apiVersion\": \"v1\",\n",
    "    \"kind\": \"Service\",\n",
    "    \"metadata\": {\n",
    "        \"name\": \"scheduler\"\n",
    "    },\n",
    "    \"spec\": {\n",
    "        \"selector\": {\n",
    "            \"app\": \"notebook\"\n",
    "        },\n",
    "        \"ports\": [\n",
    "            {\n",
    "                \"port\": 8787,\n",
    "                \"targetPort\": 8787\n",
    "            }\n",
    "        ],\n",
    "        \"type\": \"ClusterIP\"\n",
    "    }\n",
    "}\n",
    "\n",
    "pykube.Service(api,service).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can point the ingress to the service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingress = {\n",
    "  \"apiVersion\": \"extensions/v1beta1\", \n",
    "  \"kind\": \"Ingress\", \n",
    "  \"metadata\": {\n",
    "    \"name\": \"scheduler-ingress\", \n",
    "    \"annotations\": {\n",
    "      \"traefik.ingress.kubernetes.io/rewrite-target\": \"/\"\n",
    "    }\n",
    "  },\n",
    "  \"spec\": {\n",
    "    \"rules\": [\n",
    "      {\n",
    "        \"http\": {\n",
    "          \"paths\": [\n",
    "            {\n",
    "              \"path\": \"/scheduler\", \n",
    "              \"backend\": {\n",
    "                \"serviceName\": \"scheduler\", \n",
    "                \"servicePort\": 8787\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  }, \n",
    "}\n",
    "\n",
    "pykube.Ingress(api,ingress).create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have rewrited the target url with \"/\" in order to request the right url to the service.\n",
    "\n",
    "- If we access [localhost/scheduler](http://localhost/scheduler) it will redirect to the service calling \"scheduler-ip:application-port/\"\n",
    "\n",
    "- So, it allow us to acess [localhost/scheduler/status](http://localhost/scheduler/status) and it will call the service with \"application-ip:application-port/status\".\n",
    "\n",
    "We need to do this due two things:\n",
    "1. Load the statics files of the application\n",
    "> If we don't rewrite the \"/scheduler\", the site try to get \"/static\" but the Ingress will call \"/scheduler/static\" inside the service, wich doesn't exists.\n",
    "2. Organize the ingress in order to have more than one application exposed by ingresses.\n",
    "> We can organize many applications in the same IP address only by calling \"ip-address/application-name/index\" and it will redirect the request to the correct service and port."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Acess the Ingress Url and see the dashboard working\n",
    "Now you can acess the ingress [dashboard](http://localhost/scheduler/status) url and then run the cells bellow to see it showing the processes running in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask import delayed\n",
    "import time\n",
    "\n",
    "def inc(x):\n",
    "    time.sleep(0.01)\n",
    "    return x+1\n",
    "def red(x):\n",
    "    time.sleep(0.01)\n",
    "    return x-1\n",
    "a=1\n",
    "for i in range(100):\n",
    "    b=delayed(inc)(a)\n",
    "    a=delayed(red)(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.73 s, sys: 82.1 ms, total: 6.82 s\n",
      "Wall time: 6.87 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "a.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Close and clean everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed.scheduler - INFO - Remove client Client-3e7b4f7a-a825-11ea-8023-52f9387825f0\n",
      "distributed.scheduler - INFO - Remove client Client-3e7b4f7a-a825-11ea-8023-52f9387825f0\n",
      "distributed.scheduler - INFO - Close client connection: Client-3e7b4f7a-a825-11ea-8023-52f9387825f0\n",
      "distributed.scheduler - INFO - Scheduler closing...\n",
      "distributed.scheduler - INFO - Scheduler closing all comms\n",
      "distributed.scheduler - INFO - Remove worker <Worker 'tcp://10.42.0.29:43861', name: 0, memory: 0, processing: 0>\n",
      "distributed.core - INFO - Removing comms to tcp://10.42.0.29:43861\n",
      "distributed.scheduler - INFO - Lost all workers\n"
     ]
    }
   ],
   "source": [
    "client.close()\n",
    "cluster.close()\n",
    "\n",
    "pykube.Ingress(api,ingress).delete()\n",
    "pykube.Service(api,service).delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
